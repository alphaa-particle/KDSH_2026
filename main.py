import torch
import csv
import os
from torch.utils.data import DataLoader

# Import your custom modules
from src.data_loader import NovelBackstoryDataset, collate_fn
from src.model import BDHConsistencyClassifier
from src.trainer import run_pipeline

# Import tokenizer from the bdh package
# Ensure bdh/__init__.py exists for this to work
from bdh import BDHTokenizer 

def main():
    # ---------------------------------------------------------
    # 1. Configuration
    # ---------------------------------------------------------
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Running on: {DEVICE}")

    # Paths updated to match your git commit structure
    NOVELS_DIR = "./data/novels"
    TRAIN_CSV = "./data/train.csv"   # Fixed path
    TEST_CSV = "./data/test.csv"     # Fixed path
    CONFIG_PATH = "./bdh/config.json"

    # ---------------------------------------------------------
    # 2. Initialize Tokenizer & Datasets
    # ---------------------------------------------------------
    print("Loading Tokenizer...")
    # 'bdh-base' maps to DistilBERT in our bdh/__init__.py wrapper
    tokenizer = BDHTokenizer.from_pretrained("bdh-base") 
    
    print("Preparing Datasets...")
    # We verify files exist before crashing
    if not os.path.exists(TRAIN_CSV) or not os.path.exists(TEST_CSV):
        raise FileNotFoundError("Could not find train.csv or test.csv in ./data/")

    train_ds = NovelBackstoryDataset(NOVELS_DIR, TRAIN_CSV, tokenizer)
    test_ds = NovelBackstoryDataset(NOVELS_DIR, TEST_CSV, tokenizer)
    
    # Quick sanity check
    print(f"Sample Input: {train_ds[0]['input_ids'].shape}")
    print(f"Label: {train_ds[0].get('labels')}")

    # Dataloaders
    # batch_size=4 is usually better than 1 for speed, if your GPU allows
    train_loader = DataLoader(train_ds, batch_size=4, collate_fn=collate_fn, shuffle=True)
    test_loader = DataLoader(test_ds, batch_size=4, collate_fn=collate_fn)

    # ---------------------------------------------------------
    # 3. Initialize Model
    # ---------------------------------------------------------
    print("Initializing Model...")
    model = BDHConsistencyClassifier(config_path=CONFIG_PATH).to(DEVICE)
    
    # AdamW is standard for Transformers
    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)

    # ---------------------------------------------------------
    # 4. Training Loop
    # ---------------------------------------------------------
    EPOCHS = 1 # Sanity Check with 1 epoch; increase as needed

    for epoch in range(EPOCHS):
        print(f"\nEpoch {epoch+1}/{EPOCHS}")
        avg_loss = run_pipeline(model, train_loader, tokenizer, DEVICE, mode="train", optimizer=optimizer)
        print(f"Epoch {epoch+1} Average Loss: {avg_loss:.4f}")
        
    # ---------------------------------------------------------
    # 5. Final Evaluation & Submission
    # ---------------------------------------------------------
    print("\nGenerating Submission...")
    predictions = run_pipeline(model, test_loader, tokenizer, DEVICE, mode="test")
    
    # Save results to CSV
    output_file = "results.csv"
    print(f"Saving predictions to {output_file}...")
    
    with open(output_file, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["Story ID", "Prediction", "Rationale"])
        
        # Iterate through predictions and match with story_ids
        for i, pred in enumerate(predictions):
            # Safe access to story_id
            story_id = test_ds.data.iloc[i].get('id', i)
            writer.writerow([story_id, int(pred), "Generated by BDH Recurrent State"])

    print("Done!")

if __name__ == "__main__":
    main()